import openai
import json
import os
from argparse import ArgumentParser

import pandas as pd
from langchain.prompts import PromptTemplate  
from langchain.chains import LLMChain
# from langchain.callbacks import wandb_tracing_enabled
from langchain_community.callbacks import wandb_tracing_enabled
# from langchain.chat_models import ChatOpenAI
from langchain_openai import ChatOpenAI
from langchain_openai import ChatOpenAI


import mysql.connector

def fetch_schema_and_data():
    # Connect to MySQL database
    conn = mysql.connector.connect(
        host="34.93.244.9",
        user="root",
        password="12345678",
        database="newschema"
    )

    # Create a cursor object to execute SQL queries
    cursor = conn.cursor()

    # Initialize dictionaries to store schema and data
    schema_data = {}
    
    # Fetch table names in the database
    cursor.execute("SHOW TABLES")
    tables = cursor.fetchall()

    # Iterate over tables and fetch schema and data
    for table in tables:
        table_name = table[0]

        # Fetch table schema
        cursor.execute(f"DESCRIBE {table_name}")
        schema = cursor.fetchall()

        # Fetch data from the table
        cursor.execute(f"SELECT * FROM {table_name}")
        data = cursor.fetchall()

        # Store schema and data in dictionary
        schema_data[table_name] = {'schema': schema, 'data': data}

    # Close cursor and connection
    cursor.close()
    conn.close()

    # Return schema and data
    return schema_data


# result = fetch_schema_and_data()
# print(result)



def chat(system, user):
  assert isinstance(system, str), "`system` should be a string"
  assert isinstance(user, str), "`user_assistant` should be a string"
  system_msg = [{"role": "system", "content": system}]
  user_msgs = [{"role": "user", "content": user}]

  msgs = system_msg + user_msgs
  response = openai.ChatCompletion.create(model="gpt-3.5-turbo",
                                          messages=msgs)
  status_code = response["choices"][0]["finish_reason"]
  assert status_code == "stop", f"The status code was {status_code}."
  return response["choices"][0]["message"]["content"]


# Data Profilling

source_df = pd.read_csv("dumbscmap.csv")
uploading_file ="dumbscmap.csv" 
print(source_df)


response_fn_test = chat("You are a data engineer , and you have use openai and pandasai to analyse the data.",
                        f"""
                          You are an assistant to generate python code. 
                          Lets think step by step

                          Important: for all the analysis you need to use any 
                          Important: For all the analysis, you need to use langchain  or pandasAI framework

                          0. You have a table to profile or summarize the data.
                          1. What is the number of rows in the table?
                          2. Provide the column names and their corresponding datatypes by visualizing the value in it.
                          3. Display a few lines of the table.
                          4. Determine the count of null values and the count of empty  row_values.
                          5. Based on the data types identified:
                              -- For numeric data, find the maximum and minimum values.
                              -- For columns (having data type string or varchar ) with repeated 2 or 3 unique values, count the occurrences 
                          of each unique value and try to  plot using those , generate appropriate graphs (bar plot or cirular plot)
                          6. write a paragraph of 5 to 6 lines on the data-set by using following points
                          --- what's the first thing coming in your mind when you are visualizing the data 
                          ---The data is based on which area or field
                          ---what do you thing , from where this data would have taken
                          ---any overview you are getting from data 
                          --- you can use above analysis to make your work easy
                              
                          You can load the dataset from {uploading_file}]
                          python:
                          """)

# print(response_fn_test)

generated_code =  str(response_fn_test)
print(generated_code)

# def exec_AI_code(generated_code):
#     try:
#         #executing the python code generated by AI
#         exec(generated_code)
#     except Exception as e:
#         # Capture and print the error message
#         if e:
#             error_message = str(e)
#             response_fn_test = chat("You are a data engineer , and you have use openai and pandasai to analyse the data." , f"debug and try to run , error :{error_message}") 
#         else:
#             print("analysed successfully")

# exec_AI_code(generated_code)

# Schema mapping and transformation
source_df = pd.read_csv("dumbscmap.csv")
print(source_df)


sample_df = pd.read_csv("sample1.csv")
print(sample_df)


OpenAI_API_KEY = "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"

# prompt to talk with AI and generate code
template = """You are an assistant to generate code. 

Lets think step by step

1. You are given two tables. Source and  Sample.
2. Task is to generate a target table which has exactly the same number of columns as sample table and same number of rows as source table
3. Map source column names to sample column names based on the content
4. For each column in the sample table, identify which column matches from source table and find the transformation needed from source to sample table
5. Use pandas in built functions or regex and transform the column into sample table format.
6. Apply mobile transformations(xxx-xxx-xxxx) simillar to the sample table format. 
7. Always transform dates into format of sample table
8. Do not change the source,sample table values. Instead, find the transformations and apply it on the target table. 
9. Do not perform merge or concat, as the tables are huge.
10. The column names in the sample table might not match exactly in the source table. identify the columns based on the column values.
11. when ever not getting any row value in source table make it as null 
12. Generate python code to create target table by reading source.csv, sample.csv.

Few rows of Source and Sample tables:

Source - {source_row}
Sample - {sample_row}
 
Python Code:
"""
prompt = PromptTemplate(
    template=template, input_variables=["source_row" , "sample_row"]
)

llm = ChatOpenAI(openai_api_key=OpenAI_API_KEY, model="gpt-4")
llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)
source_row = source_df.iloc[:10].to_json()
sample_row = sample_df.iloc[:10].to_json()
print(sample_row)
response = llm_chain.run(
    {"source_row": source_row ,  "sample_row": sample_row}
)
print(response)

# exec_AI_code(response)